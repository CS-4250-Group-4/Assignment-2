1. Run crawler.py first for the desired seeds to fill their respective repository folders
2. Run pageRank.py to collect the required data to calculate page rank and to save it linkDict and pageDict files
3. Run CalcPageRank.py to calculate the page rank for each page of the given repository
4. Move all downloaded pages out of their repository folder and into the main repository folder (Just called "repository")
5. Run retrievalSystem.py to first index the desired domain and then retrieve relevant documents